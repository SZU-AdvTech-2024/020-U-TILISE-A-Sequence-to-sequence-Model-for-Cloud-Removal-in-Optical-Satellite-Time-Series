date_list = ['01-30','02-19','03-02','04-09','05-04','06-28','07-18','08-12','09-01','10-26','11-25','12-30']
BANDS = []
for date in date_list:
  BANDS.append("shenzhen_mosaic_2020-" + date + "_B2")
  BANDS.append("shenzhen_mosaic_2020-" + date + "_B3")
  BANDS.append("shenzhen_mosaic_2020-" + date + "_B4")
  BANDS.append("shenzhen_mosaic_2020-" + date + "_B8")
  BANDS.append("shenzhen_mosaic_2020-" + date + "_days")
print(len(BANDS))

KERNEL_SIZE = 128
KERNEL_SHAPE = [KERNEL_SIZE, KERNEL_SIZE]
kernel_buffer = [KERNEL_SIZE//2, KERNEL_SIZE//2]   # [64, 64]

image_name_prefix = "shenzhen_mosaic2020_all_month_buffer_subregion128_" # 压缩文件前缀名，不用改

subregion_collection_list = ['sub_region_0', 'sub_region_1','sub_region_12','sub_region_13','sub_region_4','sub_region_5','sub_region_6','sub_region_7','sub_region_8','sub_region_9','sub_region_10','sub_region_11''sub_region_12','sub_region_13','sub_region_14','sub_region_15','sub_region_16','sub_region_17','sub_region_18','sub_region_19','sub_region_20', 'sub_region_21'] # 改成子区域名称，即subregion_collection_list里面存储的是[“sub_region_0”, “sub_region_1”, …, “sub_region_21”]
length = 21 # 改成子区域的数量，即22

# 循环遍历子区域集合中的每个子区域
for i in range(length):
  # 获取当前子区域
  #feature = ee.Feature(subregion_collection_list.get(i)) # 这行与gee有关，删掉
  name = subregion_collection_list[i]# 这里的name改成子区域名字，即name = subregion_collection[i]

  print(name)

# doPrediction(image_name_prefix+name+"_", asset_folder, kernel_buffer, name)
# # asset_folder是存储到gee的路径，不用管

# doPrediction（）方法对数据进行预测
def doPrediction(out_image_base, user_folder, kernel_buffer, region_name):
  """Perform inference on exported imagery, upload to Earth Engine."""

  print('Looking for TFRecord files...')

  # # Get a list of all the files in the output bucket.
  # filesList = !gsutil ls 'gs://'{BUCKET}'/'{FOLDER}'/'{region_name} # 这里要改成读取本地文件的路径
  # # print("filesList:", filesList)
  import os
  # 本地文件路径
  folder_path = r'E:\shenzhen_mosaic'

  # 获取文件列表
  filesList = os.listdir(folder_path)

  # 打印文件列表
  print("filesList:", filesList)

  # Get only the files generated by the image export.
  exportFilesList = [s for s in filesList if out_image_base in s]

  # Get the list of image files and the JSON mixer file.
  imageFilesList = []
  jsonFile = None  # 地理位置信息，不用管
  for f in exportFilesList:
    if f.endswith('.tfrecord.gz'):
      imageFilesList.append(f)
    elif f.endswith('.json'):
      jsonFile = f

  # Make sure the files are in the right order.
  imageFilesList.sort()

  from pprint import pprint
  print(imageFilesList)
  print("jsonFile:", jsonFile)

  # import json
  # # Load the contents of the mixer file to a JSON object.
  # jsonText = None # 地理位置信息，不用管
  # print("jsonText:", jsonText)
  #
  # # Get a single string w/ newlines from the IPython.utils.text.SList
  # mixer = json.loads(jsonText.nlstr) # 地理位置信息，不用管
  # pprint(mixer)
  # patches = mixer['totalPatches'] # 地理位置信息，不用管

  # Get set up for prediction.
  x_buffer = int(kernel_buffer[0] / 2)
  y_buffer = int(kernel_buffer[1] / 2)

  buffered_shape = [
      KERNEL_SHAPE[0] + kernel_buffer[0],
      KERNEL_SHAPE[1] + kernel_buffer[1]]

  import tensorflow as tf

  imageColumns = [
    tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.float32)
    # tf.io.FixedLenFeature(shape=buffered_shape, dtype=tf.int64)
      for k in BANDS
  ] # 构建数据列表

  imageFeaturesDict = dict(zip(BANDS, imageColumns)) # 根据数据列表构建数据格式

  def parse_image(example_proto):
    return tf.io.parse_single_example(example_proto, imageFeaturesDict) # 根据数据格式解压数据

  def toTupleImage(inputs):  # 将数据转为图像格式
    print("inputs:", inputs)
    inputsList = [inputs.get(key) for key in BANDS]

    # 获取所有日期的键（假设日期按照顺序排列）
    date_keys = list(inputs.keys())[::5]  # 每5个张量为一组
    print(date_keys)
    stacked_tensors = []

    # 遍历日期键列表，按照日期将张量堆叠成形状为(5, 192, 192)的张量
    for key in date_keys:
      date_tensors = [inputs[key], inputs[key.replace('_B2', '_B3')], inputs[key.replace('_B2', '_B4')], inputs[key.replace('_B2', '_B8')], inputs[key.replace('_B2', '_days')]]
      stacked_tensors.append(tf.stack(date_tensors, axis=0))

    stacked = tf.stack(stacked_tensors, axis=0)
    stacked = tf.transpose(stacked, [0, 2, 3, 1])
    print("stacked.shape:", stacked.shape) # 堆叠完的形状应该为(12, 192, 192, 5)
    return stacked

   # Create a dataset from the TFRecord file(s) in Cloud Storage.
  imageDataset = tf.data.TFRecordDataset(imageFilesList, compression_type='GZIP') # 读取.gz压缩格式的文件，构建数据集
  imageDataset = imageDataset.map(parse_image, num_parallel_calls=5) # 用.map函数对上一步构建的数据集中的压缩数据进行解压
  imageDataset = imageDataset.map(toTupleImage).batch(1) # 用.map函数对上一步解压好的数据集中的所有数据进行转换，转成tensor格式，并且通过.batch(1)构建batch_size为1的数据集。
  print("imageDataset.shape:",imageDataset)

  # Perform inference.
  print('Running predictions...')

  import torch
  input_data=None
  predictions = []
  for data in imageDataset: # 遍历读取数据集
    # print(data.shape)   # (1, 12, 192, 192, 5)
    # print(type(data))   # <class 'tensorflow.python.framework.ops.EagerTensor'>
    # print(data[0,:,0,0,4:5])
    # print(data[...,:4].numpy().min(), data[..., :4].numpy().max())
    input_data = torch.from_numpy(data.numpy().transpose(0, 1, 4, 2, 3)) # 通过.transpose转置将数据集的格式转换为模型输入格式

out = get_out(input_data, input_data[:,:,:4,::], model) # get_out（）方法是用滑动窗口对原始序列长度为12的数据做适当的截取，以截取符合模型输入的长度，得到所有结果后再完整的序列长度为12的预测结果返回到 out 中

# 下面是得到结果后的处理，根据你的实际情况去修改
pre = out.permute(0, 1, 3, 4, 2)[0]
predictions.append(pre)
del input_data, out, pre

  predictions = np.stack(predictions, axis=0)
  ……

doPrediction(image_name_prefix+name+"_", asset_folder, kernel_buffer, name)
# asset_folder是存储到gee的路径，不用管

# get_out（）方法仅供参考，可以在get_out（）方法中对数据形状进行裁剪，把（192，192）裁成（128，128），也可以不裁，得到（192，192）的结果之后，在拼接的时候再裁，我这里没有裁，我放到上面省略号后面，上传gee时处理了，你可以根据自己的需要来处理。
def get_out(images, targets, model):
    # 将数据长度固定为 10，并且输入模型前要对数据做云量筛选
    T = images.shape[1]
    min_length = 5
    max_length = 10
    # out = torch.zeros(targets.shape, dtype=torch.float32).cuda(non_blocking=True).float()
    out = torch.zeros(targets.shape, dtype=torch.float32).float()

    if T < min_length:
        print("序列长度小于" + str(min_length))
        # 舍弃当前数据，跳出当前循环，继续下一个循环
        # 所有数据中没有时间长度小于 5 的数据
        return None
    elif T < max_length:
        # print("T < max_length:")
        # 使用最后一帧填充 ，使其序列长度为 10
        padding_length = max_length - T
        padding_value = images[:, -1:, ...]  # 使用最后一帧进行填充

        # 对 x 进行填充
        # padding = torch.zeros(images.shape[0], 10 - T, *images.shape[2:]).cuda(non_blocking=True).float()   # 用零填充
        padding = padding_value.repeat(1, padding_length, 1, 1, 1)
        images = torch.cat((images, padding), dim=1)
        # print("images.shape:", images.shape)

        out_ = model(images.cuda())
        out = out_[:, :T].detach().cpu()
        del out_
    elif T == 10:
        # print("T == 10:")
        out_ = model(images.cuda())
        out = out_.detach().cpu()
        del out_
    else:
        # print("T > max_length:")
        # 时间长度大于 10 ，滑动窗口，分批处理
        t_start = 0
        t_end = max_length
        stride = max_length // 2  # 滑动窗口的步长

        # 计算云量，并进行误差比较，从误差最小的开始替换
        cloud_mask = torch.where(images[:, :, :1, ...] == 1, torch.ones_like(images[:, :, :1, ...]),
                                 torch.zeros_like(images[:, :, :1, ...]))
        cloud_coverage = torch.mean(cloud_mask, dim=(0, 2, 3, 4))

        t_start_old = t_start
        t_end_old = t_end

        while t_end_old != T:
            out_0 = model(images[:, t_start:t_end].cuda())
            out_ = out_0.detach().cpu()
            del out_0

            if t_start == 0:
                out[:, t_start:t_end] = out_
            else:
                # 滑动窗口重叠部分选择误差最小进行替换
                # 找到那些已经在前一时窗和当前时窗中处理过的帧的索引，即重叠处理过的帧的索引，索引范围为 0-(T-1)
                t_overlap = sorted(set(range(t_start_old, t_end_old)) & set(range(t_start, t_end)))
                error = torch.mean(
                    torch.abs(out[:, t_overlap[0]:
                                     t_overlap[-1] + 1] - out_[:, t_overlap[0] - t_start:t_overlap[-1] - t_start + 1]
                              ),
                    dim=(0, 2, 3, 4)
                )

                # t_switch表示前一次和当前预测之间差异最小的帧在整个时间序列中的索引
                t_switch = torch.argmin(error).item() + t_start
                # 将当前预测的结果中从重叠差异最小处开始，替换部分与上一次预测的结果重叠的部分，同时，本次预测中不与上次重叠的部分也保存在最终预测结果中
                out[:, t_switch:t_end] = out_[:, (t_switch - t_start)::]
                del out_

                t_start_old = t_start
                t_end_old = t_end

            # 计算下一个窗口位置
            if t_end + stride <= T:
                # 剩余长度大于滑动步长 ，则滑动窗口向后移动 5 ，滑动窗口长度为 10 ，但移动的步长为 5
                t_start += stride
                t_end += stride

                # 根据云概率确定滑动窗口的开始帧，如果滑动后第一帧图像的云概率大于 0.1 则寻找前后 3 张云概率最小的作为第一帧
                if cloud_coverage[t_start] > 0.1:
                    dt = math.ceil(stride / 2)
                    left = max(0, t_start - dt)
                    right = min(t_start + dt + 1, T)  # 当 right 作为索引切片的右边时，取不到最后一个，因此这里要多 + 1，才能确保下面的切片可以取到右边的第 dt 个

                    t_candidates = (cloud_coverage[left:right] == cloud_coverage[left:right].min()
                                    ).nonzero(as_tuple=True)[0] + left
                    # print("t_candidates:", t_candidates)   # t_candidates: tensor([4, 7, 8], device='cuda:0')

                    t_start = t_candidates[torch.argmin(torch.abs(t_candidates - t_start))].item()
                    t_end = t_start + max_length

                    if t_end > T:
                        t_start = T - max_length
                        t_end = T
            else:
                # 最后剩余不足 10 的部分，从后往前取 10 的长度，得到的结果覆盖前面重复的部分
                t_start = T - max_length
                t_end = T
    # print("out.shape:", out.shape)   # out.shape: torch.Size([1, 15, 4, 128, 128])
    out.shape: torch.Size([1, 15, 4, 128, 128])
    return out